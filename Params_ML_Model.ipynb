{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJM88Up28VP3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "\n",
        "# Generate a synthetic dataset\n",
        "X, y = make_classification(n_samples=200, n_features=10, n_informative=8, n_redundant=2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Genetic Algorithm Parameters\n",
        "population_size = 10\n",
        "generations = 20\n",
        "mutation_rate = 0.1\n",
        "\n",
        "# Initialize population with random hyperparameters\n",
        "def initialize_population(size):\n",
        "    population = []\n",
        "    for _ in range(size):\n",
        "        # Random values for C and gamma\n",
        "        C = np.random.uniform(0.1, 10.0)\n",
        "        gamma = np.random.uniform(0.001, 1.0)\n",
        "        population.append((C, gamma))\n",
        "    return population\n",
        "\n",
        "# Fitness function: evaluate model accuracy\n",
        "def fitness(individual):\n",
        "    C, gamma = individual\n",
        "    model = SVC(C=C, gamma=gamma)\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    return accuracy_score(y_test, predictions)\n",
        "\n",
        "# Selection: Choose the best individuals\n",
        "def select_population(population, fitness_scores, num_select):\n",
        "    sorted_population = [x for _, x in sorted(zip(fitness_scores, population), reverse=True)]\n",
        "    return sorted_population[:num_select]\n",
        "\n",
        "# Crossover: Combine two parents to create offspring\n",
        "def crossover(parent1, parent2):\n",
        "    child1 = (parent1[0], parent2[1])  # Swap one parameter\n",
        "    child2 = (parent2[0], parent1[1])\n",
        "    return child1, child2\n",
        "\n",
        "# Mutation: Randomly alter a parameter\n",
        "def mutate(individual, rate):\n",
        "    if np.random.rand() < rate:\n",
        "        C, gamma = individual\n",
        "        # Mutate C or gamma\n",
        "        if np.random.rand() < 0.5:\n",
        "            C = np.random.uniform(0.1, 10.0)\n",
        "        else:\n",
        "            gamma = np.random.uniform(0.001, 1.0)\n",
        "        return (C, gamma)\n",
        "    return individual\n",
        "\n",
        "# Main Genetic Algorithm\n",
        "# Main Genetic Algorithm\n",
        "population = initialize_population(population_size)\n",
        "\n",
        "for generation in range(generations):\n",
        "    # Evaluate fitness for each individual\n",
        "    fitness_scores = [fitness(individual) for individual in population]\n",
        "    print(f\"Generation {generation + 1}: Best Accuracy = {max(fitness_scores):.4f}\")\n",
        "\n",
        "    # Select the best individuals\n",
        "    selected_population = select_population(population, fitness_scores, population_size // 2)\n",
        "\n",
        "    # Create the next generation\n",
        "    next_generation = []\n",
        "    while len(next_generation) < population_size:\n",
        "        parent1, parent2 = random.sample(selected_population, 2)\n",
        "        child1, child2 = crossover(parent1, parent2)\n",
        "        next_generation.extend([child1, child2])\n",
        "\n",
        "    # Apply mutation\n",
        "    population = [mutate(individual, mutation_rate) for individual in next_generation]\n",
        "\n",
        "# Final evaluation\n",
        "best_individual = max(population, key=fitness)\n",
        "print(\"\\nOptimized Parameters:\")\n",
        "print(f\"C: {best_individual[0]:.4f}, Gamma: {best_individual[1]:.4f}\")\n",
        "print(f\"Best Accuracy: {fitness(best_individual):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOmpVV5w8ho6",
        "outputId": "021157e6-ef38-44dd-f220-39da7c4ab0b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1: Best Accuracy = 0.8000\n",
            "Generation 2: Best Accuracy = 0.8000\n",
            "Generation 3: Best Accuracy = 0.8000\n",
            "Generation 4: Best Accuracy = 0.7833\n",
            "Generation 5: Best Accuracy = 0.7833\n",
            "Generation 6: Best Accuracy = 0.7833\n",
            "Generation 7: Best Accuracy = 0.7833\n",
            "Generation 8: Best Accuracy = 0.7833\n",
            "Generation 9: Best Accuracy = 0.7833\n",
            "Generation 10: Best Accuracy = 0.7833\n",
            "Generation 11: Best Accuracy = 0.7833\n",
            "Generation 12: Best Accuracy = 0.7833\n",
            "Generation 13: Best Accuracy = 0.7833\n",
            "Generation 14: Best Accuracy = 0.7833\n",
            "Generation 15: Best Accuracy = 0.7833\n",
            "Generation 16: Best Accuracy = 0.7833\n",
            "Generation 17: Best Accuracy = 0.7833\n",
            "Generation 18: Best Accuracy = 0.7833\n",
            "Generation 19: Best Accuracy = 0.7833\n",
            "Generation 20: Best Accuracy = 0.7833\n",
            "\n",
            "Optimized Parameters:\n",
            "C: 9.3351, Gamma: 0.6071\n",
            "Best Accuracy: 0.7833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Genetic Algorithm (GA) is a search heuristic inspired by the process of natural selection. It is used to solve optimization problems by evolving solutions over generations. When applied to machine learning, GA can be used to optimize hyperparameters, such as learning rates, regularization strengths, and number of layers.\n",
        "\n",
        "Steps in Genetic Algorithm:\n",
        "Initialization:\n",
        "\n",
        "Create an initial population of solutions (e.g., parameter sets).\n",
        "Fitness Function:\n",
        "\n",
        "Evaluate how well each solution performs (e.g., using model accuracy on validation data).\n",
        "Selection:\n",
        "\n",
        "Choose the best solutions to propagate to the next generation.\n",
        "Crossover:\n",
        "\n",
        "Combine parts of two solutions to create new solutions.\n",
        "Mutation:\n",
        "\n",
        "Introduce small random changes to solutions to maintain diversity.\n",
        "Termination:\n",
        "\n",
        "Stop when a satisfactory solution is found or after a fixed number of generations.\n",
        "\n",
        "\n",
        "Explanation of Code:\n",
        "Dataset Creation:\n",
        "\n",
        "The make_classification function generates synthetic data for testing the algorithm.\n",
        "Population Initialization:\n",
        "\n",
        "Randomly initializes C and gamma values for each individual in the population.\n",
        "Fitness Function:\n",
        "\n",
        "Evaluates the accuracy of the SVM model for each individual.\n",
        "Selection:\n",
        "\n",
        "Picks the top-performing individuals to ensure strong candidates propagate.\n",
        "Crossover:\n",
        "\n",
        "Combines parts of two individuals to produce offspring with characteristics from both parents.\n",
        "Mutation:\n",
        "\n",
        "Randomly alters C or gamma to explore new solutions and prevent premature convergence.\n",
        "Optimization:\n",
        "\n",
        "Iterates over generations to improve the population by applying selection, crossover, and mutation.\n",
        "Output:\n",
        "\n",
        "Prints the best parameters and accuracy at each generation and the final optimized solution.\n",
        "Functions Purpose:\n",
        "initialize_population: Generates a random starting population.\n",
        "fitness: Measures how \"fit\" an individual is (model accuracy).\n",
        "select_population: Retains the best-performing solutions for breeding.\n",
        "crossover: Creates new solutions by combining traits from parents.\n",
        "mutate: Introduces randomness to maintain diversity.\n",
        "max: Finds the best individual in the population.\n",
        "Why Use GA for Hyperparameter Optimization?\n",
        "Handles Non-linearity: GAs explore complex search spaces effectively.\n",
        "Avoids Local Optima: Randomness in mutation prevents being stuck in suboptimal solutions.\n",
        "Automated Search: Eliminates the need for manual trial and error for hyperparameter tuning.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A-uxXiq48hsf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}